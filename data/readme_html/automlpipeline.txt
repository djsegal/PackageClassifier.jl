<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content p-5" itemprop="text"><table>
<thead>
<tr>
<th align="center"><strong>Documentation</strong></th>
<th align="center"><strong>Build Status</strong></th>
<th align="center"><strong>Help</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://ibm.github.io/AutoMLPipeline.jl/latest/" rel="nofollow"><img src="https://camo.githubusercontent.com/3e353c26ddfe819150acbc732248f4f2a37f5175/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg" style="max-width:100%;"></a> <a href="https://ibm.github.io/AutoMLPipeline.jl/stable/" rel="nofollow"><img src="https://camo.githubusercontent.com/f7b92a177c912c1cc007fc9b40f17ff3ee3bb414/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg" style="max-width:100%;"></a></td>
<td align="center"><a href="https://travis-ci.org/IBM/AutoMLPipeline.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/3c02883a92466f0062a9f99589ebbad3d5508f10/68747470733a2f2f7472617669732d63692e6f72672f49424d2f4175746f4d4c506970656c696e652e6a6c2e7376673f6272616e63683d6d6173746572" alt="" data-canonical-src="https://travis-ci.org/IBM/AutoMLPipeline.jl.svg?branch=master" style="max-width:100%;"></a> <a href="https://codecov.io/gh/IBM/AutoMLPipeline.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/f0d23d41992f373432d1169a8250daaa30a594f1/68747470733a2f2f636f6465636f762e696f2f67682f49424d2f4175746f4d4c506970656c696e652e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="" data-canonical-src="https://codecov.io/gh/IBM/AutoMLPipeline.jl/branch/master/graph/badge.svg" style="max-width:100%;"></a></td>
<td align="center"><a href="https://julialang.slack.com" rel="nofollow"><img src="https://camo.githubusercontent.com/24d16c31ff9f7628be0e050b793afd8b2458029c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230736c61636b2d79656c6c6f772e737667" alt="" data-canonical-src="https://img.shields.io/badge/chat-on%20slack-yellow.svg" style="max-width:100%;"></a> <a href="https://gitter.im/AutoMLPipelineLearning/community" rel="nofollow"><img src="https://camo.githubusercontent.com/294d47fbbec4af4c7dee97eb1028569fc07ef7df/68747470733a2f2f6261646765732e6769747465722e696d2f7070616c6d65732f54534d4c2e6a6c2e737667" alt="" data-canonical-src="https://badges.gitter.im/ppalmes/TSML.jl.svg" style="max-width:100%;"></a></td>
</tr>
</tbody>
</table>
<h3><a id="user-content-automlpipeline-amlp" class="anchor" aria-hidden="true" href="#automlpipeline-amlp"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>AutoMLPipeline (AMLP)</h3>
<p>is a package that makes it trivial to create complex ML pipeline structures using simple expressions. AMLP leverages on the built-in macro programming features of Julia to symbolically process, manipulate pipeline expressions, and automatically discover optimal structures for machine learning prediction and classification.</p>
<p>To illustrate, here is a pipeline expression and evaluation of a typical machine learning workflow that extracts numerical features (numf) for ICA (independent component analysis) and PCA (principal component analysis) transformations, respectively, concatentated with the hot-bit encoding (ohe) of categorical features (catf) of a given data for RF modeling:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> ica) <span class="pl-k">|&gt;</span> rf
julia<span class="pl-k">&gt;</span> <span class="pl-c1">fit!</span>(model,Xtrain,Ytrain)
julia<span class="pl-k">&gt;</span> prediction <span class="pl-k">=</span> <span class="pl-c1">transform!</span>(model,Xtest)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,prediction,Ytest)
julia<span class="pl-k">&gt;</span> <span class="pl-c1">crossvalidate</span>(model,X,Y,<span class="pl-s"><span class="pl-pds">"</span>balanced_accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<h3><a id="user-content-motivations" class="anchor" aria-hidden="true" href="#motivations"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Motivations</h3>
<p>The typical workflow in machine learning
classification or prediction requires
some or combination of the following
preprocessing steps together with modeling:</p>
<ul>
<li>feature extraction (e.g. ica, pca, svd)</li>
<li>feature transformation (e.g. normalization, scaling, ohe)</li>
<li>feature selection (anova, correlation)</li>
<li>modeling (rf, adaboost, xgboost, lm, svm, mlp)</li>
</ul>
<p>Each step has several choices of functions
to use together with their corresponding
parameters. Optimizing the performance of the
entire pipeline is a combinatorial search
of the proper order and combination of preprocessing
steps, optimization of their corresponding
parameters, together with searching for
the optimal model and its hyper-parameters.</p>
<p>Because of close dependencies among various
steps, we can consider the entire process
to be a pipeline optimization problem (POP).
POP requires simultaneous optimization of pipeline
structure and parameter adaptation of its elements.
As a consequence, having an elegant way to
express pipeline structure can help lessen
the complexity in the management and analysis
of the wide-array of choices of optimization routines.</p>
<p>The target of future work will be the
implementations of different pipeline
optimization algorithms ranging from
evolutionary approaches, integer
programming (discrete choices of POP elements),
tree/graph search, and hyper-parameter search.</p>
<h3><a id="user-content-package-features" class="anchor" aria-hidden="true" href="#package-features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Package Features</h3>
<ul>
<li>Pipeline API that allows high-level description of processing workflow</li>
<li>Common API wrappers for ML libs including Scikitlearn, DecisionTree, etc</li>
<li>Symbolic pipeline parsing for easy expression
of complexed pipeline structures</li>
<li>Easily extensible architecture by overloading just two main interfaces: fit! and transform!</li>
<li>Meta-ensembles that allows composition of
ensembles of ensembles (recursively if needed)
for robust prediction routines</li>
<li>Categorical and numerical feature selectors for
specialized preprocessing routines based on types</li>
</ul>
<h3><a id="user-content-installation" class="anchor" aria-hidden="true" href="#installation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Installation</h3>
<p>AutoMLPipeline is in the Julia Official package registry.
The latest release can be installed at the Julia
prompt using Julia's package management which is triggered
by pressing <code>]</code> at the julia prompt:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> ]
(v1<span class="pl-c1">.0</span>) pkg<span class="pl-k">&gt;</span> add AutoMLPipeline</pre></div>
<p>or</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Pkg
julia<span class="pl-k">&gt;</span> <span class="pl-s"><span class="pl-pds"><span class="pl-c1">pkg</span>"</span>add AutoMLPipeline<span class="pl-pds">"</span></span></pre></div>
<p>or</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Pkg
julia<span class="pl-k">&gt;</span> Pkg<span class="pl-k">.</span><span class="pl-c1">add</span>(<span class="pl-s"><span class="pl-pds">"</span>AutoMLPipeline<span class="pl-pds">"</span></span>)</pre></div>
<h3><a id="user-content-sample-usage-of-amlp" class="anchor" aria-hidden="true" href="#sample-usage-of-amlp"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sample Usage of AMLP</h3>
<p>Below outlines some typical way to preprocess and model any dataset.</p>
<h4><a id="user-content-1-load-data" class="anchor" aria-hidden="true" href="#1-load-data"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. Load Data</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> Make sure that the input feature is a dataframe and the target output is a 1-D vector.</span>
<span class="pl-k">using</span> AutoMLPipeline
<span class="pl-k">using</span> CSV
profbdata <span class="pl-k">=</span> CSV<span class="pl-k">.</span><span class="pl-c1">read</span>(<span class="pl-c1">joinpath</span>(<span class="pl-c1">dirname</span>(<span class="pl-c1">pathof</span>(AutoMLPipeline)),<span class="pl-s"><span class="pl-pds">"</span>../data/profb.csv<span class="pl-pds">"</span></span>))
X <span class="pl-k">=</span> profbdata[:,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">end</span>] 
Y <span class="pl-k">=</span> profbdata[:,<span class="pl-c1">1</span>] <span class="pl-k">|&gt;</span> Vector;
<span class="pl-en">head</span>(x)<span class="pl-k">=</span><span class="pl-c1">first</span>(x,<span class="pl-c1">5</span>)
<span class="pl-c1">head</span>(profbdata)</pre></div>
<h4><a id="user-content-2-load-automlpipeline-package-and-submodules" class="anchor" aria-hidden="true" href="#2-load-automlpipeline-package-and-submodules"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. Load AutoMLPipeline package and submodules</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-k">using</span> AutoMLPipeline, AutoMLPipeline<span class="pl-k">.</span>FeatureSelectors, AutoMLPipeline<span class="pl-k">.</span>EnsembleMethods
<span class="pl-k">using</span> AutoMLPipeline<span class="pl-k">.</span>CrossValidators, AutoMLPipeline<span class="pl-k">.</span>DecisionTreeLearners, AutoMLPipeline<span class="pl-k">.</span>Pipelines
<span class="pl-k">using</span> AutoMLPipeline<span class="pl-k">.</span>BaseFilters, AutoMLPipeline<span class="pl-k">.</span>SKPreprocessors, AutoMLPipeline<span class="pl-k">.</span>Utils</pre></div>
<h4><a id="user-content-3-load-some-of-filters-transformers-learners" class="anchor" aria-hidden="true" href="#3-load-some-of-filters-transformers-learners"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. Load some of filters, transformers, learners</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span>### Decomposition</span>
pca <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>PCA<span class="pl-pds">"</span></span>); fa <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>FactorAnalysis<span class="pl-pds">"</span></span>); ica <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>FastICA<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span>### Scaler </span>
rb <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>RobustScaler<span class="pl-pds">"</span></span>); pt <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>PowerTransformer<span class="pl-pds">"</span></span>); 
norm <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>Normalizer<span class="pl-pds">"</span></span>); mx <span class="pl-k">=</span> <span class="pl-c1">SKPreprocessor</span>(<span class="pl-s"><span class="pl-pds">"</span>MinMaxScaler<span class="pl-pds">"</span></span>)

<span class="pl-c"><span class="pl-c">#</span>### categorical preprocessing</span>
ohe <span class="pl-k">=</span> <span class="pl-c1">OneHotEncoder</span>()

<span class="pl-c"><span class="pl-c">#</span>### Column selector</span>
catf <span class="pl-k">=</span> <span class="pl-c1">CatFeatureSelector</span>(); 
numf <span class="pl-k">=</span> <span class="pl-c1">NumFeatureSelector</span>()

<span class="pl-c"><span class="pl-c">#</span>### Learners</span>
rf <span class="pl-k">=</span> <span class="pl-c1">SKLearner</span>(<span class="pl-s"><span class="pl-pds">"</span>RandomForestClassifier<span class="pl-pds">"</span></span>); 
gb <span class="pl-k">=</span> <span class="pl-c1">SKLearner</span>(<span class="pl-s"><span class="pl-pds">"</span>GradientBoostingClassifier<span class="pl-pds">"</span></span>)
lsvc <span class="pl-k">=</span> <span class="pl-c1">SKLearner</span>(<span class="pl-s"><span class="pl-pds">"</span>LinearSVC<span class="pl-pds">"</span></span>);     svc <span class="pl-k">=</span> <span class="pl-c1">SKLearner</span>(<span class="pl-s"><span class="pl-pds">"</span>SVC<span class="pl-pds">"</span></span>)
mlp <span class="pl-k">=</span> <span class="pl-c1">SKLearner</span>(<span class="pl-s"><span class="pl-pds">"</span>MLPClassifier<span class="pl-pds">"</span></span>);  ada <span class="pl-k">=</span> <span class="pl-c1">SKLearner</span>(<span class="pl-s"><span class="pl-pds">"</span>AdaBoostClassifier<span class="pl-pds">"</span></span>)
jrf <span class="pl-k">=</span> <span class="pl-c1">RandomForest</span>();              vote <span class="pl-k">=</span> <span class="pl-c1">VoteEnsemble</span>();
stack <span class="pl-k">=</span> <span class="pl-c1">StackEnsemble</span>();           best <span class="pl-k">=</span> <span class="pl-c1">BestLearner</span>();</pre></div>
<p>Note: You can get a listing of available <code>SKPreprocessors</code> and <code>SKLearners</code> by invoking the following functions, respectively:</p>
<ul>
<li><code>skpreprocessors()</code></li>
<li><code>sklearners()</code></li>
</ul>
<h4><a id="user-content-4-feature-extraction-example-filter-categories-and-hot-encode-them" class="anchor" aria-hidden="true" href="#4-feature-extraction-example-filter-categories-and-hot-encode-them"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4. Feature extraction example: Filter categories and hot-encode them</h4>
<div class="highlight highlight-source-julia"><pre>pohe <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span> catf <span class="pl-k">|&gt;</span> ohe
tr <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(pohe,X,Y)
<span class="pl-c1">head</span>(tr)</pre></div>
<h4><a id="user-content-5-feature-extraction-example-filter-numeric-features-compute-ica-and-pca-features-and-combine-both-features" class="anchor" aria-hidden="true" href="#5-feature-extraction-example-filter-numeric-features-compute-ica-and-pca-features-and-combine-both-features"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>5. Feature extraction example: Filter numeric features, compute ica and pca features, and combine both features</h4>
<div class="highlight highlight-source-julia"><pre>pdec <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span> (numf <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> ica)
tr <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(pdec,X,Y)
<span class="pl-c1">head</span>(tr)</pre></div>
<h4><a id="user-content-6-an-example-of-pipeline-expression-for-classification-using-the-voting-ensemble-learner" class="anchor" aria-hidden="true" href="#6-an-example-of-pipeline-expression-for-classification-using-the-voting-ensemble-learner"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>6. An example of pipeline expression for classification using the Voting Ensemble learner</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> take all categorical columns and hotbit encode each, </span>
<span class="pl-c"><span class="pl-c">#</span> concatenate them to the numerical features,</span>
<span class="pl-c"><span class="pl-c">#</span> and feed them to the voting ensemble</span>
pvote <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span>  (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf) <span class="pl-k">|&gt;</span> vote
pred <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(pvote,X,Y)
sc<span class="pl-k">=</span><span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,pred,Y)
<span class="pl-c1">println</span>(sc)
<span class="pl-c"><span class="pl-c">#</span>## cross-validate</span>
<span class="pl-c1">crossvalidate</span>(pvote,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<p>Note: <code>crossvalidate()</code> supports the following sklearn's performance metric</p>
<ul>
<li><code>accuracy_score</code>, <code>balanced_accuracy_score</code>, <code>cohen_kappa_score</code></li>
<li><code>jaccard_score</code>, <code>matthews_corrcoef</code>, <code>hamming_loss</code>, <code>zero_one_loss</code></li>
<li><code>f1_score</code>, <code>precision_score</code>, <code>recall_score</code></li>
</ul>
<h4><a id="user-content-7-an-example-how-to-print-the-corresponding-function-call-of-the-pipeline-expression-in-6" class="anchor" aria-hidden="true" href="#7-an-example-how-to-print-the-corresponding-function-call-of-the-pipeline-expression-in-6"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>7. An example how to print the corresponding function call of the pipeline expression in 6</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">@pipelinex</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf) <span class="pl-k">|&gt;</span> vote
<span class="pl-c"><span class="pl-c">#</span> outputs: :(Pipeline(ComboPipeline(Pipeline(catf, ohe), numf), vote))</span></pre></div>
<h4><a id="user-content-8-another-example-of-a-pipeline-expression-with-more-expressions-for-random-forest-modeling" class="anchor" aria-hidden="true" href="#8-another-example-of-a-pipeline-expression-with-more-expressions-for-random-forest-modeling"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>8. Another example of a pipeline expression with more expressions for Random Forest modeling</h4>
<div class="highlight highlight-source-julia"><pre><span class="pl-c"><span class="pl-c">#</span> compute the pca, ica, fa of the numerical columns,</span>
<span class="pl-c"><span class="pl-c">#</span> combine them with the hot-bit encoded categorial features</span>
<span class="pl-c"><span class="pl-c">#</span> and feed all to the random forest classifier</span>
prf <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span>  (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> pca) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> ica) <span class="pl-k">+</span> (catf <span class="pl-k">|&gt;</span> ohe) <span class="pl-k">+</span> (numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> fa) <span class="pl-k">|&gt;</span> rf
pred <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(prf,X,Y)
<span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,pred,Y) <span class="pl-k">|&gt;</span> println
<span class="pl-c1">crossvalidate</span>(prf,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<h4><a id="user-content-9-an-example-of-a-pipeline-for-the-linear-support-vector-for-classification" class="anchor" aria-hidden="true" href="#9-an-example-of-a-pipeline-for-the-linear-support-vector-for-classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>9. An example of a pipeline for the Linear Support Vector for Classification</h4>
<div class="highlight highlight-source-julia"><pre>plsvc <span class="pl-k">=</span> <span class="pl-c1">@pipeline</span> ((numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> pca)<span class="pl-k">+</span>(numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> fa)<span class="pl-k">+</span>(numf <span class="pl-k">|&gt;</span> rb <span class="pl-k">|&gt;</span> ica)<span class="pl-k">+</span>(catf <span class="pl-k">|&gt;</span> ohe )) <span class="pl-k">|&gt;</span> lsvc
pred <span class="pl-k">=</span> <span class="pl-c1">fit_transform!</span>(plsvc,X,Y)
<span class="pl-c1">score</span>(<span class="pl-c1">:accuracy</span>,pred,Y) <span class="pl-k">|&gt;</span> println
<span class="pl-c1">crossvalidate</span>(plsvc,X,Y,<span class="pl-s"><span class="pl-pds">"</span>accuracy_score<span class="pl-pds">"</span></span>)</pre></div>
<p>Note: More examples can be found in the <em>test</em> directory of the package. Since
the code is written in Julia, you are highly encouraged to read the source
code and feel free to extend or adapt the package to your problem. Please
feel free to submit PRs to improve the package features.</p>
<h3><a id="user-content-extending-automlpipeline" class="anchor" aria-hidden="true" href="#extending-automlpipeline"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Extending AutoMLPipeline</h3>
<pre><code># If you want to add your own filter/transformer/learner, it is trivial. 
# Just take note that filters and transformers process the first 
# input features and ignores the target output while learners process both 
# the input features and target output arguments of the fit! function. 
# transform! function always expect one input argument in all cases. 

# First, import the abstract types and define your own mutable structure 
# as subtype of either Learner or Transformer. Also import the fit! and
# transform! functions to be overloaded. Also load the DataFrames package
# as the main data interchange format.

using DataFrames
using AutoMLPipeline.AbsTypes, AutoMLPipeline.Utils

import AutoMLPipeline.AbsTypes: fit!, transform!  #for function overloading 

export fit!, transform!, MyFilter

# define your filter structure
mutable struct MyFilter &lt;: Transformer
  variables here....
  function MyFilter()
      ....
  end
end

# define your fit! function. 
# filters and transformer ignore the target argument. 
# learners process both the input features and target argument.
function fit!(fl::MyFilter, inputfeatures::DataFrame, target::Vector=Vector())
     ....
end

#define your transform! function
function transform!(fl::MyFilter, inputfeatures::DataFrame)::DataFrame
     ....
end

# Note that the main data interchange format is a dataframe so transform! 
# output should always be a dataframe as well as the input for fit! and transform!.
# This is necessary so that the pipeline passes the dataframe format consistently to
# its filters/transformers/learners. Once you have this filter, you can use 
# it as part of the pipeline together with the other learners and filters.
</code></pre>
<h3><a id="user-content-feature-requests-and-contributions" class="anchor" aria-hidden="true" href="#feature-requests-and-contributions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Feature Requests and Contributions</h3>
<p>We welcome contributions, feature requests, and suggestions. Here is the link to open an <a href="https://github.com/IBM/AutoMLPipeline.jl/issues">issue</a> for any problems you encounter. If you want to contribute, please follow the guidelines in <a href="https://github.com/IBM/AutoMLPipeline.jl/blob/master/CONTRIBUTORS.md">contributors page</a>.</p>
<h3><a id="user-content-help-usage" class="anchor" aria-hidden="true" href="#help-usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Help usage</h3>
<p>Usage questions can be posted in:</p>
<ul>
<li><a href="https://julialang.org/community/" rel="nofollow">Julia Community</a></li>
<li><a href="https://gitter.im/AutoMLPipelineLearning/community" rel="nofollow">Gitter AutoMLPipeline Community</a></li>
<li><a href="https://discourse.julialang.org/" rel="nofollow">Julia Discourse forum</a></li>
</ul>
</article></div>