<div id="readme" class="md" data-path="README.md"><article class="markdown-body entry-content p-5" itemprop="text"><p><a href="https://travis-ci.org/pevnak/Mill.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/7927c87f93fba4ea09bedef0c828e9a4bf4d4ffd/68747470733a2f2f7472617669732d63692e6f72672f7065766e616b2f4d696c6c2e6a6c2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/pevnak/Mill.jl.svg?branch=master" style="max-width:100%;"></a>
<a href="https://coveralls.io/github/pevnak/Mill.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/4d4f41fe50d0f2ae4769eb13222940dfa03d4906/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f7065766e616b2f4d696c6c2e6a6c2f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/pevnak/Mill.jl/badge.svg?branch=master" style="max-width:100%;"></a>
<a href="http://codecov.io/github/Pevnak/Mill.jl?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/36347f2b722864507afdd8e8daaf6c48ca636970/687474703a2f2f636f6465636f762e696f2f6769746875622f5065766e616b2f4d696c6c2e6a6c2f636f7665726167652e7376673f6272616e63683d6d6173746572" alt="codecov.io" data-canonical-src="http://codecov.io/github/Pevnak/Mill.jl/coverage.svg?branch=master" style="max-width:100%;"></a></p>
<h1><a id="user-content-mill--multiple-instance-learning-library" class="anchor" aria-hidden="true" href="#mill--multiple-instance-learning-library"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Mill – Multiple Instance Learning Library</h1>
<p>Mill is a library build on top of Flux.jl aimed to prototype flexible multi-instance learning models as described in  [<a href="#cit1">1</a>] and  [<a href="#cit2">2</a>]</p>
<h2><a id="user-content-what-is-multiple-instance-learning-mil-problem" class="anchor" aria-hidden="true" href="#what-is-multiple-instance-learning-mil-problem"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is Multiple instance learning (MIL) problem?</h2>
<p>In the prototypical machine learning problem the input sample <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/504b1caff2d4567238b0b6e459a0d359fe40031b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78"><img src="https://camo.githubusercontent.com/504b1caff2d4567238b0b6e459a0d359fe40031b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78" alt="equation" data-canonical-src="https://latex.codecogs.com/gif.latex?x" style="max-width:100%;"></a> is a vector or matrix of a fixed dimension, or a sequence. In MIL problems the sample <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/504b1caff2d4567238b0b6e459a0d359fe40031b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78"><img src="https://camo.githubusercontent.com/504b1caff2d4567238b0b6e459a0d359fe40031b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78" alt="equation" data-canonical-src="https://latex.codecogs.com/gif.latex?x" style="max-width:100%;"></a> is a set of vectors (or matrices) <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/b2c21ee4380c72d979e09d5b9eb974992ade6aee/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253238785f31253243253230785f322532432532302e2e2e253243253230785f6e253239"><img src="https://camo.githubusercontent.com/b2c21ee4380c72d979e09d5b9eb974992ade6aee/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253238785f31253243253230785f322532432532302e2e2e253243253230785f6e253239" alt="equation" data-canonical-src="https://latex.codecogs.com/gif.latex?%28x_1%2C%20x_2%2C%20...%2C%20x_n%29" style="max-width:100%;"></a>, which means that order does not matter, and which is also the feature making MIL problems different from sequences.
Pevny and Somol has proposed simple way to solve MIL problems with neural networks. The network consists from two non-linear layers, with mean (or maximum) operation sandwiched between nonlinearities. Denoting <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/a9b53cfc70ab17fe545cf0dd93ebcac35c498af0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f665f31"><img src="https://camo.githubusercontent.com/a9b53cfc70ab17fe545cf0dd93ebcac35c498af0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f665f31" alt="equation" data-canonical-src="https://latex.codecogs.com/gif.latex?f_1" style="max-width:100%;"></a>, <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/fc33c675a7f13557f898afec42d6a52cbe2626e5/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f665f32"><img src="https://camo.githubusercontent.com/fc33c675a7f13557f898afec42d6a52cbe2626e5/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f665f32" alt="equation" data-canonical-src="https://latex.codecogs.com/gif.latex?f_2" style="max-width:100%;"></a> layers of neural network, the output is calculated as <a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/324db6a569f304ad61e0b8d4d6f7b1beddadff31/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6625323878253239253230253344253230665f322532302535436c65667425323825354366726163253742312537442537426e25374425354373756d5f25374269253344312537442535452537426e253744253230665f31253238785f692532392535437269676874253239"><img src="https://camo.githubusercontent.com/324db6a569f304ad61e0b8d4d6f7b1beddadff31/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6625323878253239253230253344253230665f322532302535436c65667425323825354366726163253742312537442537426e25374425354373756d5f25374269253344312537442535452537426e253744253230665f31253238785f692532392535437269676874253239" alt="equation" data-canonical-src="https://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20f_2%20%5Cleft%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20f_1%28x_i%29%5Cright%29" style="max-width:100%;"></a>. In [<a href="#cit3">3</a>], authors have further extended the universal approximation theorem to MIL problems.</p>
<h3><a id="user-content-multiple-instance-learning-on-musk-1" class="anchor" aria-hidden="true" href="#multiple-instance-learning-on-musk-1"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multiple instance learning on Musk 1</h3>
<p>Musk dataset is a classic problem of the field used in publication [<a href="#cit4">4</a>], which has given the class of problems its name.
Below is a little walk-through how to solve the problem using Mill library. The full example is shown in <a href="example/musk.jl">example/musk.jl</a>.</p>
<p>Let's start by importing all libraries</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> FileIO, JLD2, Statistics, Mill, Flux
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Flux<span class="pl-k">:</span> throttle, <span class="pl-c1">@epochs</span>
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Mill<span class="pl-k">:</span> reflectinmodel
julia<span class="pl-k">&gt;</span> <span class="pl-k">using</span> Base<span class="pl-k">.</span>Iterators<span class="pl-k">:</span> repeated</pre></div>
<p>Loading a dataset from file and folding it in Mill's data-structures is done in the following function. <code>musk.jld2</code> contains matrix with features, <code>fMat</code>, the id of sample (called bag in MIL terminology) to which each instance (column in <code>fMat</code>) belongs to, and finally a label of each instance in <code>y</code>.
<code>BagNode</code> is a structure which holds feature matrix and ranges of columns of each bag. Finally, <code>BagNode</code> can be concatenated (use <code>catobs</code>) and you can get subset using <code>getindex</code>.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> fMat <span class="pl-k">=</span> <span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>example/musk.jld2<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>fMat<span class="pl-pds">"</span></span>);      <span class="pl-c"><span class="pl-c">#</span> matrix with instances, each column is one sample</span>
julia<span class="pl-k">&gt;</span> bagids <span class="pl-k">=</span> <span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>example/musk.jld2<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>bagids<span class="pl-pds">"</span></span>);  <span class="pl-c"><span class="pl-c">#</span> ties instances to bags</span>
julia<span class="pl-k">&gt;</span> x <span class="pl-k">=</span> <span class="pl-c1">BagNode</span>(<span class="pl-c1">ArrayNode</span>(fMat), bagids);          <span class="pl-c"><span class="pl-c">#</span> create BagDataset</span>
julia<span class="pl-k">&gt;</span> y <span class="pl-k">=</span> <span class="pl-c1">load</span>(<span class="pl-s"><span class="pl-pds">"</span>example/musk.jld2<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>y<span class="pl-pds">"</span></span>);            <span class="pl-c"><span class="pl-c">#</span> load labels</span>
julia<span class="pl-k">&gt;</span> y <span class="pl-k">=</span> <span class="pl-c1">map</span>(i <span class="pl-k">-&gt;</span> <span class="pl-c1">maximum</span>(y[i]) <span class="pl-k">+</span> <span class="pl-c1">1</span>, x<span class="pl-k">.</span>bags);       <span class="pl-c"><span class="pl-c">#</span> create labels on bags</span>
julia<span class="pl-k">&gt;</span> y_oh <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">onehotbatch</span>(y, <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span>);               <span class="pl-c"><span class="pl-c">#</span> one-hot encoding</span></pre></div>
<p>Once we have data, we can manually create a model. <code>BagModel</code> is designed to implement a basic multi-instance learning model as described above. Below, we use a simple model, where instances are first passed through a single layer with 10 neurons (input dimension is 166) with <code>tanh</code> non-linearity, then we use <code>mean</code> and <code>max</code> aggregation functions simultaneously (for some problems, max is better then mean, therefore we use both), and then we use one layer with 10 neurons and <code>tanh</code> nonlinearity followed by output linear layer with 2 neurons (output dimension).</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> model <span class="pl-k">=</span> <span class="pl-c1">BagModel</span>(
    <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">166</span>, <span class="pl-c1">10</span>, Flux<span class="pl-k">.</span>tanh)),                      <span class="pl-c"><span class="pl-c">#</span> model on the level of Flows</span>
    <span class="pl-c1">SegmentedMeanMax</span>(<span class="pl-c1">10</span>),                                       <span class="pl-c"><span class="pl-c">#</span> aggregation</span>
    <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">20</span>, <span class="pl-c1">10</span>, Flux<span class="pl-k">.</span>tanh), <span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>, <span class="pl-c1">2</span>))))  <span class="pl-c"><span class="pl-c">#</span> model on the level of bags</span>

BagModel
  ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">166</span>, <span class="pl-c1">10</span>, NNlib<span class="pl-k">.</span>tanh))
  ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">10</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">10</span>)⟩
  └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">20</span>, <span class="pl-c1">10</span>, NNlib<span class="pl-k">.</span>tanh), <span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>, <span class="pl-c1">2</span>)))</pre></div>
<p>The loss function is standard <code>cross-entropy</code>:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">logitcrossentropy</span>(<span class="pl-c1">model</span>(x)<span class="pl-k">.</span>data, y_oh);</pre></div>
<p>Finally, we put everything together. The below code should resemble an example from <code>Flux.jl</code> library.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> evalcb <span class="pl-k">=</span> () <span class="pl-k">-&gt;</span> <span class="pl-c1">@show</span>(<span class="pl-c1">loss</span>(x, y_oh));
julia<span class="pl-k">&gt;</span> opt <span class="pl-k">=</span> Flux<span class="pl-k">.</span><span class="pl-c1">ADAM</span>();
julia<span class="pl-k">&gt;</span> <span class="pl-c1">@epochs</span> <span class="pl-c1">10</span> Flux<span class="pl-k">.</span><span class="pl-c1">train!</span>(loss, <span class="pl-c1">params</span>(model), <span class="pl-c1">repeated</span>((x, y_oh), <span class="pl-c1">100</span>), opt, cb<span class="pl-k">=</span><span class="pl-c1">throttle</span>(evalcb, <span class="pl-c1">1</span>))

[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">1</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">87.793724</span>f0
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">2</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">4.3207192</span>f0
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">3</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">4.2778687</span>f0
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">4</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">0.662226</span>f0
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">5</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">5.76351</span>f<span class="pl-k">-</span><span class="pl-c1">6</span>
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">6</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">3.8146973</span>f<span class="pl-k">-</span><span class="pl-c1">6</span>
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">7</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">2.8195589</span>f<span class="pl-k">-</span><span class="pl-c1">6</span>
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">8</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">2.4878461</span>f<span class="pl-k">-</span><span class="pl-c1">6</span>
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">9</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">2.1561332</span>f<span class="pl-k">-</span><span class="pl-c1">6</span>
[ Info<span class="pl-k">:</span> Epoch <span class="pl-c1">10</span>
<span class="pl-en">loss</span>(x, y_oh) <span class="pl-k">=</span> <span class="pl-c1">1.7414923</span>f<span class="pl-k">-</span><span class="pl-c1">6</span></pre></div>
<p>Because we did not leave any data for validation, we can only calculate error on the training data, which should be not so surprisingly low.</p>
<div class="highlight highlight-source-julia"><pre><span class="pl-c1">mean</span>(<span class="pl-c1">mapslices</span>(argmax, <span class="pl-c1">model</span>(x)<span class="pl-k">.</span>data, dims<span class="pl-k">=</span><span class="pl-c1">1</span>)<span class="pl-k">'</span> <span class="pl-k">.!=</span> y)

<span class="pl-c1">0.0</span></pre></div>
<h3><a id="user-content-more-complicated-models" class="anchor" aria-hidden="true" href="#more-complicated-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>More complicated models</h3>
<p>The main advantage of the Mill library is that it allows to arbitrarily nest and cross-product <code>BagModels</code>, as is described in Theorem 5 of [<a href="#cit3">3</a>].
Let's start the demonstration by nesting two MIL problems. The outer MIL model contains three samples. The first sample contains another bag (inner MIL) problem with two instances, the second sample contains two inner bags with total of three instances, and finally the third sample contains two inner bags with four instances.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> ds <span class="pl-k">=</span> <span class="pl-c1">BagNode</span>(<span class="pl-c1">BagNode</span>(<span class="pl-c1">ArrayNode</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">4</span>,<span class="pl-c1">10</span>)),[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span>,<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">4</span>,<span class="pl-c1">5</span><span class="pl-k">:</span><span class="pl-c1">5</span>,<span class="pl-c1">6</span><span class="pl-k">:</span><span class="pl-c1">7</span>,<span class="pl-c1">8</span><span class="pl-k">:</span><span class="pl-c1">10</span>]),[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">3</span>,<span class="pl-c1">4</span><span class="pl-k">:</span><span class="pl-c1">5</span>])
BagNode with <span class="pl-c1">3</span> <span class="pl-c1">bag</span>(s)
  └── BagNode with <span class="pl-c1">5</span> <span class="pl-c1">bag</span>(s)
        └── <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">4</span>, <span class="pl-c1">10</span>)</pre></div>
<p>We can create the model manually as in the case of Musk as</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> m <span class="pl-k">=</span> <span class="pl-c1">BagModel</span>(
    <span class="pl-c1">BagModel</span>(
        <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">4</span>, <span class="pl-c1">3</span>, Flux<span class="pl-k">.</span>relu)),   
        <span class="pl-c1">SegmentedMeanMax</span>(<span class="pl-c1">3</span>),
        <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, Flux<span class="pl-k">.</span>relu))),
    <span class="pl-c1">SegmentedMeanMax</span>(<span class="pl-c1">3</span>),
    <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, Flux<span class="pl-k">.</span>relu), <span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>,<span class="pl-c1">2</span>))))

BagModel
  ├── BagModel
  │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">4</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Chain</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu), <span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>, <span class="pl-c1">2</span>)))</pre></div>
<p>and we can apply the model as</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">m</span>(ds)

<span class="pl-c1">ArrayNode</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>)</pre></div>
<p>Since constructions of large models can be a process prone to errors, there is a function <code>reflectinmodel</code> which tries to automatize it keeping track of dimensions. It accepts a first parameter a sample <code>ds</code>, the second is a function returning layer (or set of layers) with input dimension <code>d</code>, and the third function is a function returning aggregation functions for <code>BagModel</code>. Using the function on the above example creates a model:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> m <span class="pl-k">=</span> <span class="pl-c1">reflectinmodel</span>(ds, d <span class="pl-k">-&gt;</span> <span class="pl-c1">Dense</span>(d, <span class="pl-c1">5</span>, relu), d <span class="pl-k">-&gt;</span> <span class="pl-c1">SegmentedMeanMax</span>(d))

BagModel
  ├── BagModel
  │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">4</span>, <span class="pl-c1">5</span>, NNlib<span class="pl-k">.</span>relu))
  │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">5</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">5</span>)⟩
  │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>, <span class="pl-c1">5</span>, NNlib<span class="pl-k">.</span>relu))
  ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">5</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">5</span>)⟩
  └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">10</span>, <span class="pl-c1">5</span>, NNlib<span class="pl-k">.</span>relu))</pre></div>
<p>Let's test the model</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> <span class="pl-c1">m</span>(ds)<span class="pl-k">.</span>data

<span class="pl-c1">5</span><span class="pl-k">×</span><span class="pl-c1">3</span> Array{Float32,<span class="pl-c1">2</span>}<span class="pl-k">:</span>
 <span class="pl-c1">0.0542484</span>   <span class="pl-c1">0.733629</span>  <span class="pl-c1">0.553823</span>
 <span class="pl-c1">0.062246</span>    <span class="pl-c1">0.866254</span>  <span class="pl-c1">1.03062</span> 
 <span class="pl-c1">0.027454</span>    <span class="pl-c1">1.04703</span>   <span class="pl-c1">1.63135</span> 
 <span class="pl-c1">0.00796955</span>  <span class="pl-c1">0.36415</span>   <span class="pl-c1">1.18108</span> 
 <span class="pl-c1">0.034735</span>    <span class="pl-c1">0.17383</span>   <span class="pl-c1">0.0</span></pre></div>
<h3><a id="user-content-even-more-complicated-models" class="anchor" aria-hidden="true" href="#even-more-complicated-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Even more complicated models</h3>
<p>As already mentioned above, the datasets can contain Cartesian products of MIL and normal (non-MIL) problems. Let's do a quick demo.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> ds <span class="pl-k">=</span> <span class="pl-c1">BagNode</span>(
    <span class="pl-c1">TreeNode</span>(
        (<span class="pl-c1">BagNode</span>(<span class="pl-c1">ArrayNode</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">4</span>,<span class="pl-c1">10</span>)),[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span>,<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">4</span>,<span class="pl-c1">5</span><span class="pl-k">:</span><span class="pl-c1">5</span>,<span class="pl-c1">6</span><span class="pl-k">:</span><span class="pl-c1">7</span>,<span class="pl-c1">8</span><span class="pl-k">:</span><span class="pl-c1">10</span>]),
        <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">3</span>,<span class="pl-c1">5</span>)),
        <span class="pl-c1">BagNode</span>(
            <span class="pl-c1">BagNode</span>(<span class="pl-c1">ArrayNode</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">30</span>)),[i<span class="pl-k">:</span>i<span class="pl-k">+</span><span class="pl-c1">1</span> <span class="pl-k">for</span> i <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">30</span>]),
            [<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">3</span>,<span class="pl-c1">4</span><span class="pl-k">:</span><span class="pl-c1">6</span>,<span class="pl-c1">7</span><span class="pl-k">:</span><span class="pl-c1">9</span>,<span class="pl-c1">10</span><span class="pl-k">:</span><span class="pl-c1">12</span>,<span class="pl-c1">13</span><span class="pl-k">:</span><span class="pl-c1">15</span>]),
        <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">randn</span>(<span class="pl-c1">2</span>,<span class="pl-c1">5</span>)))),
    [<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">1</span>,<span class="pl-c1">2</span><span class="pl-k">:</span><span class="pl-c1">3</span>,<span class="pl-c1">4</span><span class="pl-k">:</span><span class="pl-c1">5</span>])

BagNode with <span class="pl-c1">3</span> <span class="pl-c1">bag</span>(s)
  └── TreeNode
        ├── BagNode with <span class="pl-c1">5</span> <span class="pl-c1">bag</span>(s)
        │     └── <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">4</span>, <span class="pl-c1">10</span>)
        ├── <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">3</span>, <span class="pl-c1">5</span>)
        ├── BagNode with <span class="pl-c1">5</span> <span class="pl-c1">bag</span>(s)
        │     └── BagNode with <span class="pl-c1">15</span> <span class="pl-c1">bag</span>(s)
        │           └── <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">2</span>, <span class="pl-c1">30</span>)
        └── <span class="pl-c1">ArrayNode</span>(<span class="pl-c1">2</span>, <span class="pl-c1">5</span>)</pre></div>
<p>For this, we really want to create model automatically despite it being sub-optimal.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> m <span class="pl-k">=</span> <span class="pl-c1">reflectinmodel</span>(ds, d <span class="pl-k">-&gt;</span> <span class="pl-c1">Dense</span>(d, <span class="pl-c1">3</span>, relu), d <span class="pl-k">-&gt;</span> <span class="pl-c1">SegmentedMeanMax</span>(d))

BagModel
  ├── ProductModel (
  │     ├── BagModel
  │     │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">4</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     ├── BagModel
  │     │     ├── BagModel
  │     │     │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     │     │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     │     │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │   ) ↦  <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">12</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
</pre></div>
<h2><a id="user-content-tree-traversals" class="anchor" aria-hidden="true" href="#tree-traversals"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tree traversals</h2>
<p>The latest version also includes a convenient traversal functionality:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span>  <span class="pl-c1">show_traversal</span>(m)

BagModel []
  ├── ProductModel [W] (
  │     ├── BagModel [a]
  │     │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">4</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu)) [c]
  │     │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">3</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu)) [e]
  │     ├── BagModel [i]
  │     │     ├── BagModel [k]
  │     │     │     ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu)) [l]
  │     │     │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     │     │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     │     ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  │     │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  │     └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu)) [m]
  │   ) ↦  <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">12</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))</pre></div>
<p>This way any node in the model tree is swiftly accessible, which may come in handy when inspecting model parameters or simply deleting/replacing/inserting nodes to tree. All tree nodes are accessible by indexing with the traversal code:.</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> m[<span class="pl-s"><span class="pl-pds">"</span>k<span class="pl-pds">"</span></span>]

BagModel
  ├── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">2</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))
  ├── ⟨<span class="pl-c1">SegmentedMean</span>(<span class="pl-c1">3</span>), <span class="pl-c1">SegmentedMax</span>(<span class="pl-c1">3</span>)⟩
  └── <span class="pl-c1">ArrayModel</span>(<span class="pl-c1">Dense</span>(<span class="pl-c1">6</span>, <span class="pl-c1">3</span>, NNlib<span class="pl-k">.</span>relu))</pre></div>
<p>The following two approaches give the same result:</p>
<div class="highlight highlight-source-julia"><pre>julia<span class="pl-k">&gt;</span> m[<span class="pl-s"><span class="pl-pds">"</span>k<span class="pl-pds">"</span></span>] <span class="pl-k">===</span> m<span class="pl-k">.</span>im<span class="pl-k">.</span>ms[<span class="pl-c1">3</span>]<span class="pl-k">.</span>im

<span class="pl-c1">true</span></pre></div>
<h2><a id="user-content-default-aggregation-values" class="anchor" aria-hidden="true" href="#default-aggregation-values"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Default aggregation values</h2>
<p>With the latest version of Mill, it is also possible to work with missing data, replacing a missing bag with a default constant value, and even to learn this value as well.</p>
<h2><a id="user-content-references" class="anchor" aria-hidden="true" href="#references"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h2>
<p><a name="user-content-cit1"><b>1</b></a> <em>Discriminative models for multi-instance problems with tree-structure, Tomáš Pevný, Petr Somol, 2016</em>, <a href="https://arxiv.org/abs/1703.02868" rel="nofollow">https://arxiv.org/abs/1703.02868</a></p>
<p><a name="user-content-cit2"><b>2</b></a> <em>Using Neural Network Formalism to Solve Multiple-Instance Problems, Tomáš Pevný, Petr Somol, 2016</em>, <a href="https://arxiv.org/abs/1609.07257" rel="nofollow">https://arxiv.org/abs/1609.07257</a>.</p>
<p><a name="user-content-cit3"><b>3</b></a> <em>Approximation capability of neural networks on sets of probability measures and tree-structured data, Tomáš Pevný, Vojtěch Kovařík, 2019</em>, <a href="https://openreview.net/forum?id=HklJV3A9Ym" rel="nofollow">https://openreview.net/forum?id=HklJV3A9Ym</a></p>
<p><a name="user-content-cit4"><b>4</b></a> <em>Solving the multiple instance problem with axis-parallel rectangles, Dietterich, Thomas G., Richard H. Lathrop, and Tomás Lozano-Pérez, 1997</em></p>
</article></div>